[Simulation]
show_progress_level = blank
# blank (default)
# overall
# perrank

# Used only on blank
print_communication_trace = False
# True/False [if not 'True', it is False]

computation= True
# True/False [if not 'True', it is False]

# Default is 1
# 2 or more, it will do <(rank)/(number_of_cores_per_node)> to set the node of the rank
# Intranode lat/bw will be applied on cores of the same node.
number_of_cores_per_node=1


# booste_factor multiplies the size of all messages by its value
# Default is 1
booster_factor = @booster_factor


[TOPOLOGY]
# Network
topology = @topology
# KAHUNA (default)
# FMU
# HYBRID


eager_protocol_max_size = 65536
#eager_protocol_max_size = 262144

# FMU
number_of_fmus = @number_of_fmus

fmu_contention_model = @fmu_contention_model
# STATIC
# INTERLEAVE
# NO_CONFLICT

#fmu_pivot_value=0

fmu_bandwidth=@fmu_bandwidth
fmu_latency=@fmu_latency


internode_bandwidth=@internode_bandwidth
internode_latency=@internode_latency


# Intranode
intranode_bandwidth=0
intranode_latency=0





processing_speed=12000000000



[CollectiveAlgorithm]
# [Algorithm] Allreduce
CA_Allreduce = reduce_bcast
# reduce_bcast (default) [reduce to root -- bcast from root]
# ----------------------------------------------------------
# [Algorithm] Alltoall
CA_Alltoall = basic_linear
# basic_linear (default)
# ----------------------------------------------------------
# [Algorithm] Alltoallv
CA_Alltoallv = nbc_like_simgrid
# nbc_like_simgrid (default)
# nbc_improved [like simgrid but does not produce send/recv of messages with size = 0]
# ----------------------------------------------------------
# [Algorithm] Barrier
CA_Barrier = basic_linear
# basic_linear (default)
# ----------------------------------------------------------
# [Algorithm] Bcast
CA_Bcast = binomial_tree
# binomial_tree (default)
# ----------------------------------------------------------
# [Algorithm] Reduce
CA_Reduce = alltoroot
# alltoroot (defaut) [ranks -> root]
# ----------------------------------------------------------
